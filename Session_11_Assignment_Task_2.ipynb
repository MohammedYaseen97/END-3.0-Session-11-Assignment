{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 11 Assignment Task 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4/z5xIvrSsv9m0XSsEs/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammedYaseen97/END-3.0-Session-11-Assignment/blob/main/Session_11_Assignment_Task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJwIU1rDF8An",
        "outputId": "2676416d-a366-4b0f-d87a-49965117f04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjJlXVImGWYk",
        "outputId": "423fe84a-a1c2-4d10-bf95-d2ade8f06b5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPFgA52FGjzf",
        "outputId": "fb4b9684-771b-4eb5-edb4-e33003126ae5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj5oTQoeGm7m",
        "outputId": "75beb9f4-9a92-4ce9-b976-702b0950668b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "metadata": {
        "id": "eDnz-jdgGtuF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "vwGpxifMGxjB",
        "outputId": "29c594bc-ca8c-49b8-b23a-e7b9d35900c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e1d76288-d88d-45f6-88cd-201b3dde74c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John could not visit Sally.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5723</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I said that Bonny should do some dances from t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6605</th>\n",
              "      <td>g_81</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John hummed, and Mary sang, at equal volumes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4289</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The cat seems to be out of the bag.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2422</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This silver polishes itself.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3352</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A serious accident happened yesterday.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4304</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The dentist was persuaded to examine Pat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4172</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One of the people was dying of thirst.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4112</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The constant rain forced the abandonment of th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2952</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>I shaped a loaf from the dough.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1d76288-d88d-45f6-88cd-201b3dde74c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1d76288-d88d-45f6-88cd-201b3dde74c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1d76288-d88d-45f6-88cd-201b3dde74c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "312             bc01  ...                        John could not visit Sally.\n",
              "5723            c_13  ...  I said that Bonny should do some dances from t...\n",
              "6605            g_81  ...      John hummed, and Mary sang, at equal volumes.\n",
              "4289            ks08  ...                The cat seems to be out of the bag.\n",
              "2422            l-93  ...                       This silver polishes itself.\n",
              "3352            l-93  ...             A serious accident happened yesterday.\n",
              "4304            ks08  ...          The dentist was persuaded to examine Pat.\n",
              "4172            ks08  ...             One of the people was dying of thirst.\n",
              "4112            ks08  ...  The constant rain forced the abandonment of th...\n",
              "2952            l-93  ...                    I shaped a loaf from the dough.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kgjNw1SQG7Gt",
        "outputId": "6eca9d5a-b07e-4f03-84c9-543210c8b0d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-16a0f5f8-f177-4240-b9aa-d7c3952ebc2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2526</th>\n",
              "      <td>They rumor that he left town.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>The lions ate raw the meat.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8150</th>\n",
              "      <td>The airport yawned</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880</th>\n",
              "      <td>Ron wanted to be wearing a tuxedo to the party...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3926</th>\n",
              "      <td>Sketch by his students appeared in the magazine.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16a0f5f8-f177-4240-b9aa-d7c3952ebc2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16a0f5f8-f177-4240-b9aa-d7c3952ebc2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16a0f5f8-f177-4240-b9aa-d7c3952ebc2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "2526                      They rumor that he left town.      0\n",
              "710                         The lions ate raw the meat.      0\n",
              "8150                                 The airport yawned      0\n",
              "880   Ron wanted to be wearing a tuxedo to the party...      0\n",
              "3926   Sketch by his students appeared in the magazine.      0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "metadata": {
        "id": "qJBWLDFaHBXQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN2gmD4nHGd2",
        "outputId": "fdf8e4f0-6f0b-49c7-d8a2-3fa7d3aca5c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9blMBpoNHKMz",
        "outputId": "0004f6ba-5b29-4742-df5e-d62acbd00523"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAFoazTdHTW0",
        "outputId": "d1a3afa9-752e-4cc9-aa79-f8ac8694d49f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cpIP9TOHwvr",
        "outputId": "6535fabc-fc3b-4770-bef3-4e205e1d0ca7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qh_Ep2kH5BS",
        "outputId": "b2ead655-a81a-4244-f89d-0fa4f9b794cd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "tqD4GepzIAAx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_exMIFDZIB-p",
        "outputId": "e8578ce3-17d0-42e4-f95e-35e3541c958b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWxK8VP1ITpO",
        "outputId": "a443365e-07dc-49f9-ba2a-9a5cfe3e46b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "id": "i9pyau3jIaQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f795c37-01bc-4123-98c3-3d7e37af8c2c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "PJuerma5IbPJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "4vLDsZPuIoOn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "jU3kuE19Ittj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHdJDRhvIw7n",
        "outputId": "3ded0db7-7c6d-4b39-c03d-026a8531bb10"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:26.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:39.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:06.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:20.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.46\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:55.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:08.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:22.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.46\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:55.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:08.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:22.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.55\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:55.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:08.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:22.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:05:39 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zPGO2L-SKcFL",
        "outputId": "c225877c-b89f-43c4-84ac-eab1201a2d46"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8a7ffede-c58c-498d-a05b-e1c15902884f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.49</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0:01:20</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:01:22</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.19</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:01:22</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.13</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:22</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a7ffede-c58c-498d-a05b-e1c15902884f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a7ffede-c58c-498d-a05b-e1c15902884f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a7ffede-c58c-498d-a05b-e1c15902884f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.49         0.46           0.80       0:01:20         0:00:03\n",
              "2               0.30         0.46           0.82       0:01:22         0:00:03\n",
              "3               0.19         0.55           0.82       0:01:22         0:00:03\n",
              "4               0.13         0.58           0.83       0:01:22         0:00:03"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "E73S7LrDKglO",
        "outputId": "c70ff994-86be-48d7-b712-c1b793ccd221"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLEiBuKrK2OR",
        "outputId": "f2e61429-cd95-4da3-d7b5-4c5a43f67da2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWdqCpBzLC-W",
        "outputId": "7ce35b37-9b3f-41b4-b24d-e40d826ff278"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9Gngww-LNoj",
        "outputId": "02963754-b1ba-4eb1-b5ea-d936ce529e66"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVb6NkmXLORP",
        "outputId": "05af7d47-4eb1-42c9-9916-314cdcef711a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "p8nHk-3dLdW5",
        "outputId": "e249687e-aadf-41dc-ea76-426dc24ce34b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7WgkJWaLkOu",
        "outputId": "b9325284-b2f1-40d2-a8d3-0a77f4c107ea"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_sampler = RandomSampler(prediction_data)\n",
        "display_dataloader = DataLoader(prediction_data, sampler=display_sampler, batch_size=1)\n",
        "\n",
        "count = 0\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Predict\n",
        "for batch in display_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  print(\"Sentence : {}\".format(tokenizer.decode(b_input_ids[0])))\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  print(\"Outputs : {}\".format(np.argmax(logits[0].cpu())))\n",
        "\n",
        "  count += 1\n",
        "  if count == 5: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60M2Kgsf77T0",
        "outputId": "8240c391-2526-4129-f141-12a1e6e9a334"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence : [CLS] tabs are kept on suspected drug dealers by the fbi. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Outputs : 1\n",
            "Sentence : [CLS] those pictures of us offended us. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Outputs : 1\n",
            "Sentence : [CLS] the bills passed by the house yesterday that we objected to were vetoed. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Outputs : 1\n",
            "Sentence : [CLS] i dislike the person with whom we were talking. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Outputs : 1\n",
            "Sentence : [CLS] there is a seat available. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Outputs : 1\n"
          ]
        }
      ]
    }
  ]
}